{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75d47522",
   "metadata": {},
   "source": [
    "Humans ðŸ‘¦ show different emotions/feelings based on the situations and communicate them through facial expressions or in form of words.\n",
    "\n",
    "In Social Media like Twitter and Instagram, many people express their views through comments about a particular event/scenario and these comments may address the feelings like sadness, happiness, joy, sarcasm, fear, and many other.\n",
    "\n",
    "For a given comment/text, we are going to use classical NLP techniques and classify under which emotion that particular comment belongs!\n",
    "\n",
    "We are going to use techniques like Bag of grams, n-grams, TF-IDF, etc. for text representation and apply different classification algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6796573",
   "metadata": {},
   "source": [
    "#### About Data: Emotion Detection\n",
    "Credits: https://www.kaggle.com/datasets/praveengovi/emotions-dataset-for-nlp\n",
    "\n",
    "This data consists of two columns. - Comment - Emotion\n",
    "\n",
    "Comment are the statements or messages regarding to a particular event/situation.\n",
    "\n",
    "Emotion feature tells whether the given comment is fear ðŸ˜¨, Anger ðŸ˜¡, Joy ðŸ˜‚.\n",
    "\n",
    "As there are only 3 classes, this problem comes under the Multi-Class Classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "408ce277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d4d2e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i didnt feel humiliated</th>\n",
       "      <th>sadness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ive been feeling a little burdened lately wasn...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             i didnt feel humiliated  sadness\n",
       "0  i can go from feeling so hopeless to so damned...  sadness\n",
       "1   im grabbing a minute to post i feel greedy wrong    anger\n",
       "2  i am ever feeling nostalgic about the fireplac...     love\n",
       "3                               i am feeling grouchy    anger\n",
       "4  ive been feeling a little burdened lately wasn...  sadness"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_table('C:\\\\Users\\\\User\\\\Desktop\\\\Datasets\\\\Emotion detection\\\\train.txt', sep=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ddc728b",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = ['comment', 'emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "393731cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df, columns=column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b02302d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ive been feeling a little burdened lately wasn...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  emotion\n",
       "0  i can go from feeling so hopeless to so damned...  sadness\n",
       "1   im grabbing a minute to post i feel greedy wrong    anger\n",
       "2  i am ever feeling nostalgic about the fireplac...     love\n",
       "3                               i am feeling grouchy    anger\n",
       "4  ive been feeling a little burdened lately wasn...  sadness"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d1b6421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15999, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8925772b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "joy         5362\n",
       "sadness     4665\n",
       "anger       2159\n",
       "fear        1937\n",
       "love        1304\n",
       "surprise     572\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7615e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e4ec622",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "\n",
    "df['emotion'] = encoder.fit_transform(df['emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02e20492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ive been feeling a little burdened lately wasn...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  emotion\n",
       "0  i can go from feeling so hopeless to so damned...        4\n",
       "1   im grabbing a minute to post i feel greedy wrong        0\n",
       "2  i am ever feeling nostalgic about the fireplac...        3\n",
       "3                               i am feeling grouchy        0\n",
       "4  ive been feeling a little burdened lately wasn...        4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2801e6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(df.comment, df.emotion, test_size=0.25, random_state=0, stratify=df.emotion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b866919",
   "metadata": {},
   "source": [
    "### Without text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9cc7224",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74423a29",
   "metadata": {},
   "source": [
    "#### Attempt 1 :\n",
    "\n",
    "using the sklearn pipeline module create a classification pipeline to classify the data.\n",
    "\n",
    "#### Note:\n",
    "\n",
    "- using CountVectorizer with only trigrams.\n",
    "- use RandomForest as the classifier.\n",
    "- print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "480d6651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.15      0.24       540\n",
      "           1       0.66      0.20      0.31       484\n",
      "           2       0.40      0.88      0.55      1341\n",
      "           3       0.55      0.10      0.17       326\n",
      "           4       0.56      0.34      0.42      1166\n",
      "           5       0.68      0.09      0.16       143\n",
      "\n",
      "    accuracy                           0.45      4000\n",
      "   macro avg       0.57      0.29      0.31      4000\n",
      "weighted avg       0.52      0.45      0.40      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('cv_trigrams', CountVectorizer(ngram_range = (3,3))),\n",
    "    ('rf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7438ab94",
   "metadata": {},
   "source": [
    "#### Attempt 2 :\n",
    "\n",
    "using the sklearn pipeline module create a classification pipeline to classify the data.\n",
    "\n",
    "#### Note:\n",
    "\n",
    "- using CountVectorizer with both unigram and bigrams.\n",
    "- use RandomForest as the classifier.\n",
    "- print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76a54802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.78      0.83       540\n",
      "           1       0.90      0.74      0.81       484\n",
      "           2       0.78      0.96      0.86      1341\n",
      "           3       0.89      0.64      0.74       326\n",
      "           4       0.91      0.88      0.89      1166\n",
      "           5       0.83      0.66      0.73       143\n",
      "\n",
      "    accuracy                           0.85      4000\n",
      "   macro avg       0.87      0.78      0.81      4000\n",
      "weighted avg       0.86      0.85      0.85      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf1 = Pipeline([\n",
    "    ('cv_bigrams', CountVectorizer(ngram_range = (1,2))),\n",
    "    ('rf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "clf1.fit(X_train,y_train)\n",
    "y_pred1 = clf1.predict(X_test)\n",
    "print(classification_report(y_test,y_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb98faf",
   "metadata": {},
   "source": [
    "#### Attempt 3 :\n",
    "\n",
    "using the sklearn pipeline module create a classification pipeline to classify the data.\n",
    "\n",
    "#### Note:\n",
    "\n",
    "- using CountVectorizer with both unigram and bigrams.\n",
    "- use Multinomial Naive Bayes as the classifier.\n",
    "- print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fdd5dfbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.33      0.49       540\n",
      "           1       0.90      0.25      0.39       484\n",
      "           2       0.61      0.96      0.75      1341\n",
      "           3       0.92      0.07      0.14       326\n",
      "           4       0.67      0.89      0.77      1166\n",
      "           5       1.00      0.01      0.01       143\n",
      "\n",
      "    accuracy                           0.66      4000\n",
      "   macro avg       0.84      0.42      0.42      4000\n",
      "weighted avg       0.75      0.66      0.60      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf2 = Pipeline([\n",
    "    ('cv_bigrams', CountVectorizer(ngram_range = (1,2))),\n",
    "    ('NB', MultinomialNB())\n",
    "])\n",
    "\n",
    "clf2.fit(X_train,y_train)\n",
    "y_pred2 = clf2.predict(X_test)\n",
    "print(classification_report(y_test,y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744cabca",
   "metadata": {},
   "source": [
    "#### Attempt 4 :\n",
    "\n",
    "using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
    "\n",
    "#### Note:\n",
    "\n",
    "- using TF-IDF vectorizer for pre-processing the text.\n",
    "- use RandomForest as the classifier.\n",
    "- print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ab50165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.81      0.85       540\n",
      "           1       0.86      0.79      0.83       484\n",
      "           2       0.81      0.94      0.87      1341\n",
      "           3       0.87      0.67      0.76       326\n",
      "           4       0.92      0.88      0.90      1166\n",
      "           5       0.84      0.73      0.78       143\n",
      "\n",
      "    accuracy                           0.86      4000\n",
      "   macro avg       0.86      0.80      0.83      4000\n",
      "weighted avg       0.86      0.86      0.86      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "clf3 = Pipeline([\n",
    "    ('tf', TfidfVectorizer()),\n",
    "    ('rf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "clf3.fit(X_train,y_train)\n",
    "y_pred3 = clf3.predict(X_test)\n",
    "print(classification_report(y_test,y_pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edeb666d",
   "metadata": {},
   "source": [
    "### With text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec9220bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06a4340e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51c61266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    corpus = []\n",
    "    \n",
    "    for i in range(len(sentences)):\n",
    "        review = re.sub('[^a-zA-Z]', ' ', sentences[i])\n",
    "        review = review.lower()\n",
    "        review = review.split()\n",
    "        \n",
    "        review = [lemmatizer.lemmatize(word) for word in review if not word in stopwords.words('english')]\n",
    "        review = ' '.join(review)\n",
    "        corpus.append(review)\n",
    "    return ' '.join(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0518eddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comment'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "47677efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go feeling hopeless damned hopeful around someone care awake'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing(df['comment'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f703c86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['preprocessed_txt'] = df['comment'].apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ee5b816",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(df.preprocessed_txt, df.emotion, test_size=0.25, random_state=0, stratify=df.emotion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c75d01d",
   "metadata": {},
   "source": [
    "#### Attempt1 :\n",
    "\n",
    "using the sklearn pipeline module create a classification pipeline to classify the data.\n",
    "\n",
    "#### Note:\n",
    "\n",
    "- using CountVectorizer with both unigrams and bigrams.\n",
    "- use RandomForest as the classifier.\n",
    "- print the classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c4819f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.88       540\n",
      "           1       0.92      0.77      0.84       484\n",
      "           2       0.90      0.94      0.92      1341\n",
      "           3       0.84      0.77      0.80       326\n",
      "           4       0.94      0.94      0.94      1166\n",
      "           5       0.74      0.87      0.80       143\n",
      "\n",
      "    accuracy                           0.90      4000\n",
      "   macro avg       0.87      0.86      0.86      4000\n",
      "weighted avg       0.90      0.90      0.89      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf4 = Pipeline([\n",
    "    ('cv_bigrams', CountVectorizer(ngram_range = (1,2))),\n",
    "    ('rf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "clf4.fit(X_train,y_train)\n",
    "y_pred4 = clf4.predict(X_test)\n",
    "print(classification_report(y_test,y_pred4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68057eb3",
   "metadata": {},
   "source": [
    "#### Attempt 2 :\n",
    "\n",
    "using the sklearn pipeline module create a classification pipeline to classify the data.\n",
    "\n",
    "#### Note:\n",
    "\n",
    "- using TF-IDF vectorizer for pre-processing the text.\n",
    "- use RandomForest as the classifier.\n",
    "- print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "32798c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a639bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.85      0.86       540\n",
      "           1       0.85      0.83      0.84       484\n",
      "           2       0.87      0.92      0.90      1341\n",
      "           3       0.81      0.71      0.76       326\n",
      "           4       0.93      0.92      0.93      1166\n",
      "           5       0.77      0.77      0.77       143\n",
      "\n",
      "    accuracy                           0.88      4000\n",
      "   macro avg       0.85      0.84      0.84      4000\n",
      "weighted avg       0.88      0.88      0.88      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf5 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('rf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "clf5.fit(X_train,y_train)\n",
    "y_pred5 = clf5.predict(X_test)\n",
    "print(classification_report(y_test,y_pred5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4a195e",
   "metadata": {},
   "source": [
    "### Final Observations\n",
    "As part of this exercise we have trained the data with algorithms like Multinomial Naive Bayes and Random Forest which are most used and provide good results for text related problems.\n",
    "\n",
    "As Machine learning algorithms do not work on text data directly, we need to convert them into numeric vectors and feed that into models while training. For this purpose, we have used Bag of words(unigrams, bigrams, n-grams) and TF-IDF text representation techniques.\n",
    "\n",
    "#### Key Findings\n",
    "\n",
    "As the n_gram range keeps increasing, there's drastic fall of improvement in performance metrics.\n",
    "\n",
    "There's seen a significant improvement in results before pre-processing and after pre-processing the data.\n",
    "\n",
    "TF-IDF and Bag of words both performed equally well in performance metrics like Recall and F1-score.\n",
    "\n",
    "Random Forest performed quite well when compared to Multinomial Naive Bayes.\n",
    "\n",
    "#### Machine Learning is like a trial and error scientific method, where we keep trying all the possible algorithms we have and select the one which gives good results and satisfies the requirements like latency, interpretability, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4926ad8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
